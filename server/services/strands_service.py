"""
Strands Agent Service
ç»Ÿä¸€çš„ AWS Strands Agent æœåŠ¡ï¼Œæ”¯æŒå•agentå’Œå¤šagentæ¨¡å¼
"""
import asyncio
import json
import traceback
from typing import List, Dict, Any, Optional

from strands import Agent, tool
try:
    from strands.models import BedrockModel, AnthropicModel, OpenAIModel, OllamaModel
except ImportError:
    from strands.models import BedrockModel
    AnthropicModel = BedrockModel
    OpenAIModel = BedrockModel
    OllamaModel = BedrockModel

from services.db_service import db_service
from services.config_service import config_service
from services.websocket_service import send_to_websocket, send_to_user_websocket
from services.strands_context import SessionContextManager
from services.user_context import get_current_user_id

# å…¨å±€å˜é‡æ¥è·Ÿè¸ªå·²å‘é€çš„äº‹ä»¶ï¼Œé˜²æ­¢é‡å¤
_sent_events = set()


async def send_user_websocket_message(session_id: str, event: dict):
    """Send WebSocket message to the current user"""
    try:
        user_id = get_current_user_id()
        await send_to_user_websocket(session_id, event, user_id)
    except Exception as e:
        # Fallback to broadcast if user context is not available
        print(f"âš ï¸ User context not available, falling back to broadcast: {e}")
        await send_to_websocket(session_id, event)


async def handle_image_generation_result(tool_result_text: str, session_id: str, tool_call_id: str):
    """å¤„ç†å›¾åƒç”Ÿæˆå·¥å…·çš„ç»“æœï¼Œå¦‚æœæ£€æµ‹åˆ°å›¾åƒç”ŸæˆæˆåŠŸï¼Œåˆ™ä¿å­˜å›¾åƒæ¶ˆæ¯"""
    try:
        print(f"ğŸ” DEBUG: Checking tool result text: {tool_result_text[:200]}...")

        # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾åƒç”ŸæˆæˆåŠŸçš„æ¶ˆæ¯
        if "Image generated successfully!" in tool_result_text and "File ID:" in tool_result_text:
            print(f"ğŸ¨ DEBUG: Found image generation success message")

            # æå–æ–‡ä»¶ID
            import re
            file_id_match = re.search(r'File ID: ([^,\s]+)', tool_result_text)
            print(f"ğŸ” DEBUG: Regex match result: {file_id_match}")

            if file_id_match:
                file_id = file_id_match.group(1)
                print(f"ğŸ¨ DEBUG: Detected image generation result, file_id: {file_id}")

                # åˆ›å»ºå›¾åƒæ¶ˆæ¯æ ¼å¼
                image_message = {
                    'role': 'assistant',
                    'content': [
                        {
                            'type': 'image_url',
                            'image_url': {
                                'url': f'/api/file/{file_id}'
                            }
                        }
                    ]
                }

                # ä¿å­˜å›¾åƒæ¶ˆæ¯åˆ°æ•°æ®åº“
                try:
                    db_service.create_message(session_id, 'assistant', json.dumps(image_message))
                    print(f"âœ… Saved image message for file_id: {file_id}")
                except Exception as save_error:
                    print(f"âŒ ERROR: Failed to save image message: {save_error}")
                    traceback.print_exc()
            else:
                print(f"âŒ DEBUG: Failed to extract file_id from: {tool_result_text}")
        # æ£€æŸ¥æ˜¯å¦æ˜¯è§†é¢‘ç”ŸæˆæˆåŠŸçš„æ¶ˆæ¯
        elif "Video generated successfully!" in tool_result_text and "File ID:" in tool_result_text:
            # æå–æ–‡ä»¶ID
            import re
            file_id_match = re.search(r'File ID: `([^`]+)`', tool_result_text)
            if file_id_match:
                file_id = file_id_match.group(1)
                print(f"ğŸ¬ DEBUG: Detected video generation result, file_id: {file_id}")

                # å¯¹äºè§†é¢‘ï¼Œæˆ‘ä»¬ä¿å­˜åŒ…å«ä¸‹è½½é“¾æ¥çš„æ–‡æœ¬æ¶ˆæ¯ï¼ˆå› ä¸ºå‰ç«¯è¿˜æ²¡æœ‰ä¸“é—¨çš„è§†é¢‘æ¶ˆæ¯ç»„ä»¶ï¼‰
                # è¿™é‡Œæˆ‘ä»¬ä¸éœ€è¦é¢å¤–ä¿å­˜ï¼Œå› ä¸ºå·¥å…·è¿”å›çš„æ–‡æœ¬æ¶ˆæ¯å·²ç»åŒ…å«äº†ä¸‹è½½é“¾æ¥
                print(f"âœ… Video message will be saved as text with download link")

    except Exception as e:
        print(f"âš ï¸ Error handling generation result: {e}")
        # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“ä¸»æµç¨‹


def create_model_instance(text_model: Dict[str, Any]):
    """åˆ›å»ºæ¨¡å‹å®ä¾‹"""
    model = text_model.get('model')
    provider = text_model.get('provider')
    url = text_model.get('url')
    api_key = config_service.app_config.get(provider, {}).get("api_key", "")
    max_tokens = text_model.get('max_tokens', 8148)
    
    if provider == 'ollama':
        try:
            return OllamaModel(
                model=model,
                base_url=url,
            )
        except:
            return BedrockModel(model_id=model)
    elif provider == 'bedrock':
        region = config_service.app_config.get(provider, {}).get("region", "us-west-2")
        return BedrockModel(
            model_id=model,
            region_name=region,
            max_tokens=max_tokens,
            temperature=0
        )
    elif provider == 'anthropic':
        try:
            return AnthropicModel(
                model=model,
                api_key=api_key,
                max_tokens=max_tokens,
                temperature=0
            )
        except:
            return BedrockModel(model_id=model)
    else:
        try:
            return OpenAIModel(
                model=model,
                api_key=api_key,
                base_url=url,
                temperature=0,
                max_tokens=max_tokens,
            )
        except:
            return BedrockModel(model_id=model)


def get_specialized_agents():
    """è·å–ä¸“é—¨åŒ–agentå·¥å…·åˆ—è¡¨"""
    try:
        from tools.strands_specialized_agents import get_specialized_agents

        agents = get_specialized_agents()
        print(f"âœ… Loaded {len(agents)} specialized agents")
        for agent in agents:
            print(f"  - {agent.__name__}: {type(agent)}")
        return agents
    except Exception as e:
        print(f"âŒ Failed to load specialized agents: {e}")
        traceback.print_exc()
        return []


async def strands_agent(messages, canvas_id, session_id, text_model, image_model, video_model=None, system_prompt: str = None):
    """å•ä¸ª Strands Agent å¤„ç†"""
    try:
        model = create_model_instance(text_model)

        # åˆ›å»ºç³»ç»Ÿæç¤º
        available_tools = []

        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ ComfyUI æ¨¡å‹
        is_comfyui_model = (
            image_model.get('provider') == 'comfyui' or
            (video_model and video_model.get('provider') == 'comfyui')
        )

        print(f"ğŸ” DEBUG: is_comfyui_model = {is_comfyui_model}")
        print(f"ğŸ” DEBUG: image_model.provider = {image_model.get('provider')}")
        print(f"ğŸ” DEBUG: video_model = {video_model}")
        if video_model:
            print(f"ğŸ” DEBUG: video_model.provider = {video_model.get('provider')}")

        if is_comfyui_model:
            available_tools.append("generate_with_comfyui: Smart ComfyUI generator that automatically creates images or videos based on the selected model")
        else:
            available_tools.append("generate_image_with_context: Generate images based on text descriptions")
            if video_model:
                available_tools.append("generate_video_with_context: Generate videos based on text descriptions and optionally input images")

        tools_description = "\n".join([f"- {tool}" for tool in available_tools])

        agent_system_prompt = system_prompt or f"""
You are a professional AI assistant with image and video generation capabilities.

Available tools:
{tools_description}

When users request image or video generation:
1. Analyze their request to understand what they want
2. Create a detailed, descriptive prompt for the content
3. Use the appropriate generation tool:
   - For ComfyUI models: Use generate_with_comfyui (automatically detects image/video based on model)
   - For other providers: Use generate_image_with_context or generate_video_with_context
4. Choose appropriate aspect ratios based on the content
5. The tools support both text-to-image/video and image-to-image/video modes
6. For I2I/I2V, you can specify an input_image or use use_previous_image=True

IMPORTANT - Context Usage:
- Image tool has use_previous_image=True by default, which automatically uses the most recent image from this conversation
- Video tool has use_previous_image=True by default, which automatically uses the most recent image for I2V generation
- Use use_previous_image=TRUE when the user wants to EDIT, MODIFY, or BUILD UPON an existing image/video
- Use use_previous_image=FALSE when the user wants a COMPLETELY NEW, UNRELATED content or explicitly asks for a "new" creation
- IMPORTANT: Some models (like flux-t2i, wan-t2v) are text-only models and don't support input images. The tools will automatically ignore use_previous_image for these models
- If no previous image exists in the conversation, the tools will inform you appropriately

For other tasks, use your general knowledge and reasoning capabilities.
Be helpful, accurate, and creative in your responses.
"""

        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        user_prompt = ""
        for msg in reversed(messages):
            if msg.get('role') == 'user':
                user_prompt = msg.get('content', '')
                break

        if not user_prompt:
            user_prompt = "Hello, how can I help you?"

        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œä¼ é€’å½“å‰ç”¨æˆ·ID
        try:
            current_user_id = get_current_user_id()
        except Exception:
            current_user_id = None

        # å‡†å¤‡æ¨¡å‹ä¸Šä¸‹æ–‡
        model_context = {'image': image_model}
        if video_model:
            model_context['video'] = video_model

        with SessionContextManager(session_id, canvas_id, model_context, user_id=current_user_id):
            print(f"ğŸ’¬ Processing: {user_prompt[:50]}...")

            # åˆ›å»ºå¸¦æœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å·¥å…·
            tools = []

            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ ComfyUI æ¨¡å‹
            if is_comfyui_model:
                # ä½¿ç”¨æ™ºèƒ½ ComfyUI å·¥å…·
                from tools.strands_comfyui_generator import create_smart_comfyui_generator
                # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æ˜ç¡®é€‰æ‹©çš„è§†é¢‘æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å›¾åƒæ¨¡å‹
                comfyui_model = video_model if (video_model and video_model.get('provider') == 'comfyui') else image_model
                print(f"ğŸ” DEBUG: Selected ComfyUI model: {comfyui_model}")
                smart_comfyui_tool = create_smart_comfyui_generator(session_id, canvas_id, comfyui_model, current_user_id)
                tools.append(smart_comfyui_tool)
            else:
                # ä½¿ç”¨ä¼ ç»Ÿçš„åˆ†ç¦»å·¥å…·
                from tools.strands_image_generators import create_generate_image_with_context
                contextual_generate_image = create_generate_image_with_context(session_id, canvas_id, image_model, current_user_id)
                tools.append(contextual_generate_image)

                # æ·»åŠ è§†é¢‘ç”Ÿæˆå·¥å…·ï¼ˆå¦‚æœé…ç½®äº†è§†é¢‘æ¨¡å‹ï¼‰
                if video_model:
                    from tools.strands_video_generators import create_generate_video_with_context
                    contextual_generate_video = create_generate_video_with_context(session_id, canvas_id, video_model, current_user_id)
                    tools.append(contextual_generate_video)

            print(f"ğŸ” DEBUG: Using tools: {[tool.__name__ for tool in tools]}")

            # åˆ›å»ºå¸¦æœ‰ä¸Šä¸‹æ–‡å·¥å…·çš„agent
            agent = Agent(
                model=model,
                tools=tools,
                system_prompt=agent_system_prompt
            )

            print(f"âœ… Agent created with {len(tools)} tools")

            # ä½¿ç”¨å¼‚æ­¥æµå¼è°ƒç”¨æ›¿ä»£åŒæ­¥è°ƒç”¨
            print("ğŸ” DEBUG: Calling agent with async streaming...")

            try:
                # ä½¿ç”¨å¼‚æ­¥æµå¼è°ƒç”¨
                response_parts = []
                tool_results = []  # æ”¶é›†å·¥å…·è°ƒç”¨ç»“æœ
                async for event in agent.stream_async(user_prompt):
                    # å¤„ç†æµå¼äº‹ä»¶å¹¶å‘é€åˆ°å‰ç«¯
                    await handle_agent_event(event, session_id)

                    # æ”¶é›†å“åº”å†…å®¹ç”¨äºä¿å­˜åˆ°æ•°æ®åº“
                    if isinstance(event, dict) and 'event' in event and 'contentBlockDelta' in event['event']:
                        delta = event['event']['contentBlockDelta']['delta']
                        if 'text' in delta:
                            response_parts.append(delta['text'])

                    # æ”¶é›†å·¥å…·è°ƒç”¨ç»“æœ
                    elif isinstance(event, dict) and 'toolResult' in event:
                        tool_result = event['toolResult']
                        if 'content' in tool_result:
                            for content in tool_result['content']:
                                if content.get('type') == 'text' and 'text' in content:
                                    tool_results.append(content['text'])
                                    print(f"ğŸ” DEBUG: Collected tool result: {content['text'][:100]}...")

                                    # å·¥å…·å·²ç»ç›´æ¥ä¿å­˜äº†å›¾åƒ/è§†é¢‘æ¶ˆæ¯ï¼Œè¿™é‡Œä¸éœ€è¦é¢å¤–å¤„ç†

                # ä¿å­˜å®Œæ•´çš„æ–‡æœ¬æ¶ˆæ¯åˆ°æ•°æ®åº“ï¼ˆåŒ…æ‹¬å·¥å…·ç»“æœï¼‰
                all_content = response_parts + tool_results
                response_text = ''.join(all_content)
                if response_text.strip():  # åªä¿å­˜éç©ºæ¶ˆæ¯
                    text_message = {
                        'role': 'assistant',
                        'content': response_text
                    }
                    db_service.create_message(session_id, 'assistant', json.dumps(text_message))
                    print(f"ğŸ” DEBUG: Saved message with {len(response_parts)} text parts and {len(tool_results)} tool results")

            except Exception as e:
                print(f"âŒ Agent error: {e}")
                await send_user_websocket_message(session_id, {
                    'type': 'error',
                    'error': str(e)
                })

        # å‘é€å®Œæˆäº‹ä»¶
        await send_user_websocket_message(session_id, {
            'type': 'done'
        })

    except Exception as e:
        print('Error in strands_agent', e)
        traceback.print_exc()
        await send_user_websocket_message(session_id, {
            'type': 'error',
            'error': str(e)
        })


async def strands_multi_agent(messages, canvas_id, session_id, text_model, image_model, video_model=None, system_prompt: str = None):
    """å¤šAgent Swarmå¤„ç†"""
    try:
        model = create_model_instance(text_model)

        # åˆ›å»ºä¸»Agentï¼Œä½¿ç”¨ä¸“é—¨åŒ–agentå·¥å…·
        orchestrator_system_prompt = system_prompt or """
You are an intelligent orchestrator agent that coordinates multiple specialized agents to handle complex tasks.

Available Specialized Agents:
- planner_agent: Creates detailed execution plans and project breakdowns
- image_designer_agent: Generates images and handles visual content creation

Your Coordination Capabilities:
- Analyze complex projects and break them down into manageable components
- Coordinate multiple specialists working together on complex projects
- Manage task dependencies, sequencing, and resource allocation
- Track progress and ensure quality across multi-step workflows
- Provide comprehensive project management and execution guidance

Routing Guidelines:
1. For planning tasks â†’ use planner_agent
2. For image/visual content â†’ use image_designer_agent
3. For complex projects â†’ coordinate specialists directly using your built-in capabilities

Always analyze the user's request and route to the most appropriate specialist(s).
You can use multiple agents in sequence for complex tasks and coordinate their work directly.
For analysis, research, or data processing tasks, use your own reasoning capabilities or route to planner_agent for structured analysis.
"""

        # åˆ›å»ºä¸“é—¨åŒ–agentsä½œä¸ºå·¥å…·
        specialized_agents = get_specialized_agents()

        print(f"ğŸ”§ Creating multi-agent with {len(specialized_agents)} specialized agents:")
        for i, agent_tool in enumerate(specialized_agents):
            agent_name = getattr(agent_tool, '__name__', str(agent_tool))
            agent_type = type(agent_tool).__name__
            print(f"  {i+1}. {agent_name} ({agent_type})")

        agent = Agent(
            model=model,
            tools=specialized_agents,
            system_prompt=orchestrator_system_prompt
        )

        print(f"âœ… Multi-agent created successfully")
        
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼ - å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        user_prompt = ""
        for msg in reversed(messages):
            if msg.get('role') == 'user':
                user_prompt = msg.get('content', '')
                break

        if not user_prompt:
            user_prompt = "Hello, how can I help you?"

        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è®¾ç½®ä¼šè¯ä¸Šä¸‹æ–‡ï¼Œä¼ é€’å½“å‰ç”¨æˆ·ID
        try:
            current_user_id = get_current_user_id()
        except Exception:
            current_user_id = None

        # å‡†å¤‡æ¨¡å‹ä¸Šä¸‹æ–‡
        model_context = {'image': image_model}
        if video_model:
            model_context['video'] = video_model

        with SessionContextManager(session_id, canvas_id, model_context, user_id=current_user_id):
            print(f"ğŸ” DEBUG: Starting multi-agent stream call with prompt: {user_prompt}")
            print(f"ğŸ” DEBUG: Session context - session_id: {session_id}, canvas_id: {canvas_id}")
            print(f"ğŸ” DEBUG: Image model: {image_model}")

            # ä½¿ç”¨å¼‚æ­¥æµå¼è°ƒç”¨æ›¿ä»£åŒæ­¥è°ƒç”¨
            print("ğŸ” DEBUG: Calling multi-agent with async streaming...")

            try:
                # ä½¿ç”¨å¼‚æ­¥æµå¼è°ƒç”¨
                response_parts = []
                tool_results = []  # æ”¶é›†å·¥å…·è°ƒç”¨ç»“æœ
                async for event in agent.stream_async(user_prompt):
                    # å¤„ç†æµå¼äº‹ä»¶å¹¶å‘é€åˆ°å‰ç«¯
                    await handle_agent_event(event, session_id)

                    # æ”¶é›†å“åº”å†…å®¹ç”¨äºä¿å­˜åˆ°æ•°æ®åº“
                    if isinstance(event, dict) and 'event' in event and 'contentBlockDelta' in event['event']:
                        delta = event['event']['contentBlockDelta']['delta']
                        if 'text' in delta:
                            response_parts.append(delta['text'])

                    # æ”¶é›†å·¥å…·è°ƒç”¨ç»“æœ
                    elif isinstance(event, dict) and 'toolResult' in event:
                        tool_result = event['toolResult']
                        if 'content' in tool_result:
                            for content in tool_result['content']:
                                if content.get('type') == 'text' and 'text' in content:
                                    tool_results.append(content['text'])
                                    print(f"ğŸ” DEBUG: Multi-agent collected tool result: {content['text'][:100]}...")

                                    # å·¥å…·å·²ç»ç›´æ¥ä¿å­˜äº†å›¾åƒ/è§†é¢‘æ¶ˆæ¯ï¼Œè¿™é‡Œä¸éœ€è¦é¢å¤–å¤„ç†

                # ä¿å­˜å®Œæ•´çš„æ–‡æœ¬æ¶ˆæ¯åˆ°æ•°æ®åº“ï¼ˆåŒ…æ‹¬å·¥å…·ç»“æœï¼‰
                all_content = response_parts + tool_results
                response_text = ''.join(all_content)
                if response_text.strip():  # åªä¿å­˜éç©ºæ¶ˆæ¯
                    text_message = {
                        'role': 'assistant',
                        'content': response_text
                    }
                    db_service.create_message(session_id, 'assistant', json.dumps(text_message))
                    print(f"ğŸ” DEBUG: Multi-agent saved message with {len(response_parts)} text parts and {len(tool_results)} tool results")

            except Exception as e:
                print(f"âŒ Multi-agent error: {e}")
                await send_user_websocket_message(session_id, {
                    'type': 'error',
                    'error': str(e)
                })

        # å‘é€å®Œæˆäº‹ä»¶
        await send_user_websocket_message(session_id, {
            'type': 'done'
        })

    except Exception as e:
        print('Error in strands_multi_agent', e)
        tb_str = traceback.format_exc()
        print(f"Full traceback:\n{tb_str}")
        traceback.print_exc()
        await send_user_websocket_message(session_id, {
            'type': 'error',
            'error': str(e)
        })


async def handle_agent_event(event, session_id):
    """å¤„ç† Agent äº‹ä»¶"""
    if not isinstance(event, dict):
        return
    
    # åªå¤„ç†é‡è¦çš„äº‹ä»¶ï¼Œå‡å°‘å™ªéŸ³
    if 'event' in event:
        inner_event = event['event']
        
        # å¤„ç†å·¥å…·è°ƒç”¨å¼€å§‹
        if 'contentBlockStart' in inner_event:
            start = inner_event['contentBlockStart']['start']
            if 'toolUse' in start:
                tool_use = start['toolUse']
                tool_call_id = tool_use.get('toolUseId', '')

                # æ£€æŸ¥æ˜¯å¦å·²ç»å‘é€è¿‡è¿™ä¸ªtool_calläº‹ä»¶
                event_key = f"tool_call_{session_id}_{tool_call_id}"
                if event_key in _sent_events:
                    print(f"ğŸ”„ Skipping duplicate tool_call event: {tool_call_id}")
                    return

                _sent_events.add(event_key)
                print(f"ğŸ”§ Tool call started: {tool_use.get('name', '')} (ID: {tool_call_id})")
                await send_user_websocket_message(session_id, {
                    'type': 'tool_call',
                    'id': tool_call_id,
                    'name': tool_use.get('name', ''),
                    'arguments': ''
                })

        # å¤„ç†æ–‡æœ¬å’Œå·¥å…·å‚æ•°å¢é‡
        elif 'contentBlockDelta' in inner_event:
            delta = inner_event['contentBlockDelta']['delta']
            if 'text' in delta:
                await send_user_websocket_message(session_id, {
                    'type': 'delta',
                    'text': delta['text']
                })
            elif 'toolUse' in delta:
                await send_user_websocket_message(session_id, {
                    'type': 'tool_call_arguments',
                    'id': '',
                    'text': delta['toolUse'].get('input', '')
                })
        
        # å¤„ç†å·¥å…·è°ƒç”¨å®Œæˆ
        elif 'contentBlockStop' in inner_event:
            stop_info = inner_event['contentBlockStop']
            if 'toolUse' in stop_info:
                print(f"ğŸ”§ Tool call completed")

    # å¤„ç†å·¥å…·è°ƒç”¨ç»“æœ
    elif 'toolResult' in event:
        tool_result = event['toolResult']
        print(f"ğŸ”§ Tool result received: {tool_result.get('toolUseId', 'unknown')}")

        # å‘é€å·¥å…·ç»“æœåˆ°å‰ç«¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if 'content' in tool_result:
            for content in tool_result['content']:
                if content.get('type') == 'text' and 'text' in content:
                    # å¯ä»¥é€‰æ‹©å‘é€å·¥å…·ç»“æœä½œä¸ºdeltaäº‹ä»¶
                    await send_user_websocket_message(session_id, {
                        'type': 'delta',
                        'text': content['text']
                    })
    
    # æ³¨é‡Šæ‰é‡å¤çš„æ–‡æœ¬å¤„ç†é€»è¾‘ï¼Œé¿å…é‡å¤å‘é€deltaäº‹ä»¶
    # elif "data" in event and "delta" in event:
    #     # å¤„ç†åŒ…å«æ–‡æœ¬çš„æ•°æ®äº‹ä»¶ï¼Œä½†é¿å…é‡å¤å¤„ç†å·²ç»åœ¨ä¸Šé¢å¤„ç†è¿‡çš„äº‹ä»¶
    #     if isinstance(event.get("data"), str) and event["data"].strip():
    #         # è¿™æ˜¯ä¸€ä¸ªåŒ…å«æ–‡æœ¬çš„æ•°æ®äº‹ä»¶
    #         await send_user_websocket_message(session_id, {
    #             'type': 'delta',
    #             'text': event["data"]
    #         })


# å‘åå…¼å®¹çš„åˆ«å
clean_strands_agent = strands_agent
handle_clean_agent_event = handle_agent_event


# æ”¯æŒå¹¶è¡Œagentçš„è¾…åŠ©å‡½æ•°
def create_parallel_agents(agent_type: str, count: int, base_config: dict) -> list:
    """åˆ›å»ºå¹¶è¡Œagenté…ç½®"""
    parallel_agents = []
    for i in range(count):
        agent_config = base_config.copy()
        agent_config['name'] = f"{agent_type}_{i+1}"
        parallel_agents.append(agent_config)
    return parallel_agents
