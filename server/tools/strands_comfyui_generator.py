"""
æ™ºèƒ½ ComfyUI ç”Ÿæˆå·¥å…·
æ ¹æ®æ¨¡å‹åç§°è‡ªåŠ¨åˆ¤æ–­æ˜¯å›¾åƒè¿˜æ˜¯è§†é¢‘ç”Ÿæˆ
"""

import os
import traceback
from typing import Dict, Any, Optional
from strands import tool
from pydantic import Field

from services.strands_context import get_session_id, get_canvas_id, get_user_id


def create_smart_comfyui_generator(session_id: str, canvas_id: str, comfyui_model: Dict[str, Any], user_id: str = None):
    """
    åˆ›å»ºæ™ºèƒ½çš„ ComfyUI ç”Ÿæˆå·¥å…·ï¼Œæ ¹æ®æ¨¡å‹è‡ªåŠ¨åˆ¤æ–­ç”Ÿæˆç±»å‹
    
    Args:
        session_id: ä¼šè¯ID
        canvas_id: ç”»å¸ƒID
        comfyui_model: ComfyUI æ¨¡å‹é…ç½®
        user_id: ç”¨æˆ·ID
    """
    
    @tool
    async def generate_with_comfyui(
        prompt: str = Field(..., description="Detailed description of what to generate"),
        aspect_ratio: str = Field(default="1:1", description="Aspect ratio (1:1, 16:9, 4:3, 3:4, 9:16)"),
        input_image: str = Field(default="", description="Input image file ID for image-to-image or image-to-video generation"),
        use_previous_image: bool = Field(default=True, description="Whether to use the most recent image from this conversation as input"),
        duration: int = Field(default=5, description="Video duration in seconds (for video generation only)")
    ) -> str:
        """
        Smart ComfyUI generator that automatically determines whether to generate images or videos
        based on the selected model. Supports both text-to-image/video and image-to-image/video generation.
        
        Model types:
        - flux-* models: Generate images
        - wan-* models: Generate videos
        
        Args:
            prompt: Detailed description of what to generate
            aspect_ratio: Aspect ratio for the output
            input_image: Input image file ID for I2I/I2V generation
            use_previous_image: Whether to use the most recent image from conversation
            duration: Video duration in seconds (for video models only)
        """
        try:
            model_name = comfyui_model.get('model', '')
            media_type = comfyui_model.get('media_type', '')
            
            print(f"ğŸ¨ğŸ¬ Smart ComfyUI Generator: model={model_name}, media_type={media_type}")
            
            # æ ¹æ®æ¨¡å‹åç§°æˆ– media_type åˆ¤æ–­ç”Ÿæˆç±»å‹
            is_video_model = (
                'wan-' in model_name.lower() or 
                'video' in model_name.lower() or 
                media_type == 'video'
            )
            
            if is_video_model:
                print(f"ğŸ¬ Detected video model, using video generation")
                # ä½¿ç”¨è§†é¢‘ç”Ÿæˆå·¥å…·
                from tools.strands_video_generators import create_generate_video_with_context
                video_generator = create_generate_video_with_context(session_id, canvas_id, comfyui_model, user_id)

                return await video_generator(
                    prompt=prompt,
                    input_image=input_image,
                    use_previous_image=use_previous_image,
                    duration=duration
                )
            else:
                print(f"ğŸ¨ Detected image model, using image generation")
                # ä½¿ç”¨å›¾åƒç”Ÿæˆå·¥å…·
                from tools.strands_image_generators import create_generate_image_with_context
                image_generator = create_generate_image_with_context(session_id, canvas_id, comfyui_model, user_id)

                return await image_generator(
                    prompt=prompt,
                    aspect_ratio=aspect_ratio,
                    input_image=input_image,
                    use_previous_image=use_previous_image
                )
                
        except Exception as e:
            print(f"âŒ Smart ComfyUI Generator error: {e}")
            traceback.print_exc()
            return f"âŒ Generation Error: {str(e)}"
    
    return generate_with_comfyui


def get_smart_comfyui_tools():
    """è¿”å›æ™ºèƒ½ ComfyUI å·¥å…·åˆ—è¡¨"""
    return [create_smart_comfyui_generator]
